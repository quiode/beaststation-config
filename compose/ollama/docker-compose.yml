services:
  ollama:
    image: ollama/ollama
    container_name: ollama
    volumes:
      - /hdd/non-critical/ollama:/root/.ollama
    restart: always
    tty: true
    runtime: nvidia
    environment:
      - TZ=Europe/Zurich
    networks:
      - ollama-internal

  open-webui:
    image: ghcr.io/open-webui/open-webui:cuda
    container_name: open-webui
    networks:
      - ollama-internal
      - ollama-external
    environment:
      - WEBUI_URL=https://chat.dominik-schwaiger.ch
      - CUSTOM_NAME=Chat
      - USE_CUDA_DOCKER=true
      - OLLAMA_BASE_URL=http://ollama:11434
      - ENABLE_OPENAI_API=false
      - TZ=Europe/Zurich
    runtime: nvidia
    volumes:
      - /hdd/critical/open-webui:/app/backend/data
      - /ssd/non-critical/open-webui/cache:/app/backend/data/cache
    depends_on:
      - ollama
    restart: always
    labels:
    - "traefik.enable=true"
    - "traefik.docker.network=ollama"
    - "traefik.http.routers.ollama.rule=Host(`chat.dominik-schwaiger.ch`)"
    - "traefik.http.routers.ollama.tls=true"
    - "traefik.http.routers.ollama.tls.certresolver=letsencrypt"

networks:
  ollama-internal:
    name: ollama-internal

  ollama-external:
    name: ollama
    external: true
